{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 0 - Título y guía rápida\n",
        "from IPython.display import Markdown, display\n",
        "try:\n",
        "    title_md = Markdown(r\"\"\"# Lab 3 — ASR + LLM + TTS end-to-end\n",
        "Este laboratorio guía la construcción de un pipeline completo que parte de audio en vivo, lo transcribe con **Whisper**, genera una respuesta corta con un **LLM local** y sintetiza voz clonada y voz base usando **Coqui TTS**.\"\"\")\n",
        "    flow_md = Markdown(\"\"\"**Flujo general:** `Audio → ASR → LLM → TTS (clonada & base)`\"\"\")\n",
        "    uso_md = Markdown(\"\"\"**Cómo usar:** ejecuta cada celda en orden. Si la grabación falla (permisos, navegador), cambia automáticamente al modo **Subir archivo** y continúa sin reiniciar el runtime.\"\"\")\n",
        "    display(title_md, flow_md, uso_md)\n",
        "    print(\"[Celda 0] Guía mostrada correctamente.\")\n",
        "except Exception as exc:\n",
        "    print(f\"[Celda 0] Error al mostrar la guía: {exc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 1 - Setup de proyecto (Drive + rutas + utils)\n",
        "import os, json, subprocess, sys, time, math, shutil, pathlib, random\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "except Exception:\n",
        "    np = None\n",
        "\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "DRIVE_MOUNTED = False\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        from google.colab import drive  # type: ignore\n",
        "        if not os.path.isdir('/content/drive'):\n",
        "            drive.mount('/content/drive')\n",
        "        elif not os.path.exists('/content/drive/MyDrive'):\n",
        "            drive.mount('/content/drive')\n",
        "        DRIVE_MOUNTED = True\n",
        "    except Exception as exc:\n",
        "        print(f\"[Celda 1] Advertencia: no fue posible montar Google Drive automáticamente: {exc}\")\n",
        "        DRIVE_MOUNTED = False\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Lab3_ASR_LLM_TTS\"\n",
        "if not IN_COLAB:\n",
        "    BASE_DIR = os.path.abspath('./Lab3_ASR_LLM_TTS_local')\n",
        "\n",
        "paths = {\n",
        "    'voice_ref': os.path.join(BASE_DIR, 'data', 'voice_ref'),\n",
        "    'audios': os.path.join(BASE_DIR, 'data', 'audios'),\n",
        "    'outputs': os.path.join(BASE_DIR, 'outputs')\n",
        "}\n",
        "for p in paths.values():\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "SPEAKER_WAV = os.path.join(paths['voice_ref'], 'voz_referencia_grabada.wav')\n",
        "QUESTION_RAW_WAV = os.path.join(paths['audios'], 'pregunta_raw.wav')\n",
        "QUESTION_WAV = os.path.join(paths['audios'], 'pregunta_16k.wav')\n",
        "CLONED_WAV = os.path.join(paths['outputs'], 'respuesta_clonada.wav')\n",
        "BASE_WAV = os.path.join(paths['outputs'], 'respuesta_base.wav')\n",
        "ASR_METRICS_PNG = os.path.join(paths['outputs'], 'asr_metrics.png')\n",
        "LLM_METRICS_PNG = os.path.join(paths['outputs'], 'llm_metrics.png')\n",
        "TTS_TIMES_PNG = os.path.join(paths['outputs'], 'tts_tiempos.png')\n",
        "RESULTS_JSON = os.path.join(paths['outputs'], 'results.json')\n",
        "\n",
        "RESULTS: Dict[str, Any] = {}\n",
        "\n",
        "def ffmpeg(*args, check=True):\n",
        "    cmd = ['ffmpeg', '-y'] + list(args)\n",
        "    try:\n",
        "        completed = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=check, text=True)\n",
        "    except FileNotFoundError:\n",
        "        raise RuntimeError('ffmpeg no está disponible en el sistema.')\n",
        "    if completed.returncode != 0 and check:\n",
        "        raise RuntimeError(f\"ffmpeg falló: {completed.stderr[-500:]}\")\n",
        "    return completed\n",
        "\n",
        "def ffprobe_duration(path: str) -> float:\n",
        "    if not os.path.exists(path):\n",
        "        return 0.0\n",
        "    cmd = ['ffprobe', '-i', path, '-show_entries', 'format=duration', '-v', 'quiet', '-of', 'csv=p=0']\n",
        "    try:\n",
        "        completed = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
        "        return float(completed.stdout.strip())\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "def to_wav_mono_16k(src: str, dst: str, sr: int = 16000):\n",
        "    if not os.path.exists(src):\n",
        "        raise FileNotFoundError(f\"Archivo de origen no encontrado: {src}\")\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    args = ['-i', src, '-ac', '1', '-ar', str(sr), dst]\n",
        "    ffmpeg(*args)\n",
        "\n",
        "def save_results(data: Dict[str, Any], path: str = RESULTS_JSON):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    try:\n",
        "        with open(path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "    except Exception as exc:\n",
        "        print(f\"[Celda 1] No fue posible guardar {path}: {exc}\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    torch.manual_seed(42)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "except Exception:\n",
        "    pass\n",
        "random.seed(42)\n",
        "\n",
        "summary = {\n",
        "    'IN_COLAB': IN_COLAB,\n",
        "    'DRIVE_MOUNTED': DRIVE_MOUNTED,\n",
        "    'BASE_DIR': BASE_DIR,\n",
        "    'paths': paths\n",
        "}\n",
        "print(\"[Celda 1] Setup completado:\")\n",
        "print(json.dumps(summary, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 2 - Dependencias y verificación\n",
        "import json, subprocess, sys, shutil, time\n",
        "packages = [\n",
        "    'openai-whisper',\n",
        "    'transformers',\n",
        "    'accelerate',\n",
        "    'sentencepiece',\n",
        "    'TTS',\n",
        "    'librosa',\n",
        "    'soundfile',\n",
        "    'jiwer',\n",
        "    'matplotlib'\n",
        "]\n",
        "install_report = {'status': 'skipped', 'detail': '', 'packages': packages}\n",
        "try:\n",
        "    start = time.time()\n",
        "    cmd = [sys.executable, '-m', 'pip', 'install'] + packages\n",
        "    completed = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    install_report['stdout_tail'] = completed.stdout.splitlines()[-20:]\n",
        "    install_report['stderr_tail'] = completed.stderr.splitlines()[-20:]\n",
        "    install_report['returncode'] = completed.returncode\n",
        "    install_report['elapsed_s'] = round(time.time() - start, 2)\n",
        "    install_report['status'] = 'ok' if completed.returncode == 0 else 'error'\n",
        "except Exception as exc:\n",
        "    install_report['status'] = 'exception'\n",
        "    install_report['detail'] = str(exc)\n",
        "\n",
        "versions = {}\n",
        "for cmd_name in ['ffmpeg', 'ffprobe']:\n",
        "    try:\n",
        "        res = subprocess.run([cmd_name, '-version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        versions[cmd_name] = res.stdout.split('\n",
        "')[0]\n",
        "    except Exception as exc:\n",
        "        versions[cmd_name] = f'No disponible: {exc}'\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    versions['torch'] = str(torch.__version__)\n",
        "    versions['cuda_available'] = bool(torch.cuda.is_available())\n",
        "except Exception as exc:\n",
        "    versions['torch'] = f'No importado: {exc}'\n",
        "\n",
        "try:\n",
        "    import transformers\n",
        "    versions['transformers'] = transformers.__version__\n",
        "except Exception as exc:\n",
        "    versions['transformers'] = f'No importado: {exc}'\n",
        "\n",
        "print('[Celda 2] Resumen de instalación/verificación:')\n",
        "print(json.dumps({'install': install_report, 'versions': versions}, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 3 - Grabación robusta record_audio() (streaming + idempotente)\n",
        "import os, base64, threading, tempfile, time, json, shutil\n",
        "from IPython.display import Javascript, display, Audio\n",
        "\n",
        "def record_audio(out_wav=None, sr=16000, autoplay=True, timeslice_ms=400):\n",
        "    \"\"\"\n",
        "    Graba audio desde el micrófono (Colab) y devuelve un WAV mono 16 kHz.\n",
        "    Requisitos:\n",
        "    - UI idempotente, streaming de chunks y conversiones con ffmpeg.\n",
        "    \"\"\"\n",
        "    if out_wav is None:\n",
        "        out_wav = os.path.join(paths['audios'], f'grabacion_{int(time.time())}.wav')\n",
        "    tmp_dir = tempfile.mkdtemp()\n",
        "    tmp_webm = os.path.join(tmp_dir, 'temp_audio.webm')\n",
        "    chunk_lock = threading.Lock()\n",
        "    chunks = []\n",
        "    done_event = threading.Event()\n",
        "    error_holder = {'message': None}\n",
        "    start_time = time.time()\n",
        "    timeout_seconds = 5 * 60\n",
        "\n",
        "    try:\n",
        "        from google.colab import output  # type: ignore\n",
        "    except Exception:\n",
        "        raise RuntimeError('record_audio solo está soportado en Google Colab con acceso al navegador.')\n",
        "\n",
        "    def push_audio_chunk(b64_chunk):\n",
        "        try:\n",
        "            data = base64.b64decode(b64_chunk)\n",
        "            with chunk_lock:\n",
        "                chunks.append(data)\n",
        "        except Exception as exc:\n",
        "            error_holder['message'] = f'Error al decodificar chunk: {exc}'\n",
        "            done_event.set()\n",
        "\n",
        "    def audio_done():\n",
        "        done_event.set()\n",
        "\n",
        "    def audio_error(msg):\n",
        "        error_holder['message'] = msg\n",
        "        done_event.set()\n",
        "\n",
        "    output.register_callback('notebook.push_audio_chunk', push_audio_chunk)\n",
        "    output.register_callback('notebook.audio_done', audio_done)\n",
        "    output.register_callback('notebook.audio_error', audio_error)\n",
        "\n",
        "    js_code = f\"\"\"\n",
        "    (async () => {{\n",
        "      try {{\n",
        "        const existing = document.getElementById('recorder-box');\n",
        "        if (existing) {{ existing.remove(); }}\n",
        "        const box = document.createElement('div');\n",
        "        box.id = 'recorder-box';\n",
        "        box.style.border = '1px solid #ddd';\n",
        "        box.style.padding = '12px';\n",
        "        box.style.margin = '8px 0';\n",
        "        box.style.borderRadius = '8px';\n",
        "        box.style.maxWidth = '320px';\n",
        "        box.style.fontFamily = 'sans-serif';\n",
        "        const title = document.createElement('div');\n",
        "        title.textContent = 'Grabación de audio (streaming)';\n",
        "        title.style.fontWeight = '600';\n",
        "        title.style.marginBottom = '8px';\n",
        "        const status = document.createElement('div');\n",
        "        status.id = 'recorder-status';\n",
        "        status.textContent = 'Listo para grabar';\n",
        "        status.style.margin = '8px 0';\n",
        "        const indicator = document.createElement('span');\n",
        "        indicator.style.display = 'inline-block';\n",
        "        indicator.style.width = '10px';\n",
        "        indicator.style.height = '10px';\n",
        "        indicator.style.borderRadius = '50%';\n",
        "        indicator.style.marginRight = '6px';\n",
        "        indicator.style.background = '#bbb';\n",
        "        status.prepend(indicator);\n",
        "        const buttons = document.createElement('div');\n",
        "        buttons.style.display = 'flex';\n",
        "        buttons.style.gap = '6px';\n",
        "        const startBtn = document.createElement('button');\n",
        "        startBtn.textContent = 'Grabar';\n",
        "        const stopBtn = document.createElement('button');\n",
        "        stopBtn.textContent = 'Parar';\n",
        "        stopBtn.disabled = true;\n",
        "        buttons.appendChild(startBtn);\n",
        "        buttons.appendChild(stopBtn);\n",
        "        const msg = document.createElement('div');\n",
        "        msg.style.fontSize = '12px';\n",
        "        msg.style.color = '#555';\n",
        "        msg.textContent = 'Si no escuchas el preview o no inicia, revisa permisos del navegador.';\n",
        "        box.appendChild(title);\n",
        "        box.appendChild(status);\n",
        "        box.appendChild(buttons);\n",
        "        box.appendChild(msg);\n",
        "        document.body.appendChild(box);\n",
        "\n",
        "        let mediaStream = null;\n",
        "        let recorder = null;\n",
        "        let watchdog = null;\n",
        "        let lastChunk = Date.now();\n",
        "        const timeslice = {int(timeslice_ms)};\n",
        "        const stopUI = (reason) => {{\n",
        "          if (recorder && recorder.state !== 'inactive') {{\n",
        "            try {{ recorder.stop(); }} catch (e) {{ console.warn(e); }}\n",
        "          }}\n",
        "          if (mediaStream) {{\n",
        "            mediaStream.getTracks().forEach(t => t.stop());\n",
        "          }}\n",
        "          if (watchdog) {{ clearInterval(watchdog); }}\n",
        "          indicator.style.background = '#bbb';\n",
        "          stopBtn.disabled = true;\n",
        "          startBtn.disabled = false;\n",
        "          if (reason) {{ status.textContent = reason; status.prepend(indicator); }}\n",
        "        }};\n",
        "\n",
        "        const handleData = (event) => {{\n",
        "          if (event.data && event.data.size) {{\n",
        "            lastChunk = Date.now();\n",
        "            const reader = new FileReader();\n",
        "            reader.onloadend = () => {{\n",
        "              const base64 = reader.result.split(',')[1];\n",
        "              google.colab.kernel.invokeFunction('notebook.push_audio_chunk', [base64], {{}});\n",
        "            }};\n",
        "            reader.readAsDataURL(event.data);\n",
        "          }}\n",
        "        }};\n",
        "\n",
        "        startBtn.onclick = async () => {{\n",
        "          msg.textContent = 'Grabando... concede permisos al micrófono si aparece un diálogo.';\n",
        "          status.textContent = 'Solicitando micrófono...';\n",
        "          status.prepend(indicator);\n",
        "          indicator.style.background = '#d33';\n",
        "          startBtn.disabled = true;\n",
        "          stopBtn.disabled = false;\n",
        "          try {{\n",
        "            mediaStream = await navigator.mediaDevices.getUserMedia({{ audio: true }});\n",
        "          }} catch (err) {{\n",
        "            google.colab.kernel.invokeFunction('notebook.audio_error', ['Permiso de micrófono denegado o no disponible.'], {{}});\n",
        "            stopUI('Permiso denegado. Usa la opción de subir archivo.');\n",
        "            return;\n",
        "          }}\n",
        "          let options = {{ mimeType: 'audio/webm;codecs=opus' }};\n",
        "          try {{\n",
        "            recorder = new MediaRecorder(mediaStream, options);\n",
        "          }} catch (err) {{\n",
        "            console.warn('MediaRecorder fallback', err);\n",
        "            recorder = new MediaRecorder(mediaStream);\n",
        "          }}\n",
        "          recorder.ondataavailable = handleData;\n",
        "          recorder.onerror = (event) => {{\n",
        "            console.error(event);\n",
        "            google.colab.kernel.invokeFunction('notebook.audio_error', ['Error de MediaRecorder: ' + event.error.message], {{}});\n",
        "            stopUI('Error de MediaRecorder. Reintenta o sube un archivo.');\n",
        "          }};\n",
        "          recorder.onstop = () => {{\n",
        "            google.colab.kernel.invokeFunction('notebook.audio_done', [], {{}});\n",
        "            stopUI('Grabación finalizada.');\n",
        "            setTimeout(() => {{\n",
        "              const box = document.getElementById('recorder-box');\n",
        "              if (box) box.remove();\n",
        "            }}, 1200);\n",
        "          }};\n",
        "          recorder.start(timeslice);\n",
        "          lastChunk = Date.now();\n",
        "          watchdog = setInterval(() => {{\n",
        "            const diff = Date.now() - lastChunk;\n",
        "            if (diff > 10000) {{\n",
        "              status.textContent = 'No se recibe audio del micro. Revisa conexión o permisos.';\n",
        "              status.prepend(indicator);\n",
        "              msg.textContent = 'Puedes detener y volver a intentar o usar subida de archivo.';\n",
        "            }}\n",
        "          }}, 2000);\n",
        "          status.textContent = 'Grabando...';\n",
        "          status.prepend(indicator);\n",
        "        }};\n",
        "\n",
        "        stopBtn.onclick = () => {{\n",
        "          stopUI('Detenido por el usuario.');\n",
        "        }};\n",
        "      }} catch (err) {{\n",
        "        console.error(err);\n",
        "        google.colab.kernel.invokeFunction('notebook.audio_error', ['Fallo inicializando el grabador: ' + err.message], {{}});\n",
        "      }}\n",
        "    }})()\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "    while True:\n",
        "        if done_event.wait(timeout=1.0):\n",
        "            break\n",
        "        if (time.time() - start_time) > timeout_seconds:\n",
        "            error_holder['message'] = 'Timeout de grabación (5 minutos).'\n",
        "            break\n",
        "    if error_holder['message']:\n",
        "        raise RuntimeError(error_holder['message'])\n",
        "    if not chunks:\n",
        "        raise RuntimeError('No se recibieron datos de audio. Usa la opción de subir archivo.')\n",
        "    with open(tmp_webm, 'wb') as f:\n",
        "        with chunk_lock:\n",
        "            for chunk in chunks:\n",
        "                f.write(chunk)\n",
        "    to_wav_mono_16k(tmp_webm, out_wav, sr=sr)\n",
        "    duration = ffprobe_duration(out_wav)\n",
        "    if autoplay:\n",
        "        try:\n",
        "            display(Audio(out_wav))\n",
        "        except Exception:\n",
        "            pass\n",
        "    print(json.dumps({'status': 'ok', 'wav_path': out_wav, 'duration_s': round(duration, 3)}, ensure_ascii=False))\n",
        "    shutil.rmtree(tmp_dir, ignore_errors=True)\n",
        "    return out_wav\n",
        "\n",
        "print('[Celda 3] Función record_audio disponible.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 4 - Voz de referencia (record / upload → SPEAKER_WAV)\n",
        "import json, traceback\n",
        "from IPython.display import Audio\n",
        "voice_summary = {'mode': 'record', 'success': False, 'path': None, 'duration_s': 0.0, 'error': None}\n",
        "if os.path.exists(SPEAKER_WAV):\n",
        "    try:\n",
        "        os.remove(SPEAKER_WAV)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    voice_path = record_audio(out_wav=SPEAKER_WAV, sr=16000, autoplay=True)\n",
        "    voice_summary.update({'success': True, 'path': voice_path, 'duration_s': round(ffprobe_duration(voice_path), 2)})\n",
        "except Exception as exc:\n",
        "    voice_summary['error'] = str(exc)\n",
        "    voice_summary['mode'] = 'upload'\n",
        "    print(f\"[Celda 4] Grabación falló: {exc}. Cambiando a modo 'upload'.\")\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            tmp_name = list(uploaded.keys())[0]\n",
        "            tmp_path = os.path.join(paths['voice_ref'], tmp_name)\n",
        "            with open(tmp_path, 'wb') as f:\n",
        "                f.write(uploaded[tmp_name])\n",
        "            to_wav_mono_16k(tmp_path, SPEAKER_WAV)\n",
        "            voice_summary.update({'success': True, 'path': SPEAKER_WAV, 'duration_s': round(ffprobe_duration(SPEAKER_WAV), 2)})\n",
        "        else:\n",
        "            print('[Celda 4] No se subió archivo alguno.')\n",
        "    except Exception as exc_upload:\n",
        "        voice_summary['error'] = f\"No se pudo subir archivo: {exc_upload}\"\n",
        "\n",
        "if voice_summary['success']:\n",
        "    RESULTS['voice_ref'] = voice_summary\n",
        "    print(json.dumps({'status': 'ok', 'path': voice_summary['path'], 'duration_s': voice_summary['duration_s']}, ensure_ascii=False))\n",
        "    try:\n",
        "        display(Audio(voice_summary['path']))\n",
        "    except Exception:\n",
        "        pass\n",
        "else:\n",
        "    print(json.dumps({'status': 'error', 'detail': voice_summary}, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 5 - Pregunta hablada + ASR (Whisper)\n",
        "import json, time\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "question_summary = {'mode': 'record', 'path': None, 'duration_s': 0.0, 'error': None}\n",
        "if os.path.exists(QUESTION_RAW_WAV):\n",
        "    try:\n",
        "        os.remove(QUESTION_RAW_WAV)\n",
        "    except Exception:\n",
        "        pass\n",
        "if os.path.exists(QUESTION_WAV):\n",
        "    try:\n",
        "        os.remove(QUESTION_WAV)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    question_path = record_audio(out_wav=QUESTION_RAW_WAV, sr=16000, autoplay=False)\n",
        "    question_summary['path'] = question_path\n",
        "except Exception as exc:\n",
        "    question_summary['error'] = str(exc)\n",
        "    question_summary['mode'] = 'upload'\n",
        "    print(f\"[Celda 5] Grabación falló: {exc}. Cambiando a modo 'upload'.\")\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            tmp_name = list(uploaded.keys())[0]\n",
        "            tmp_path = os.path.join(paths['audios'], tmp_name)\n",
        "            with open(tmp_path, 'wb') as f:\n",
        "                f.write(uploaded[tmp_name])\n",
        "            question_summary['path'] = tmp_path\n",
        "        else:\n",
        "            raise RuntimeError('No se subió ningún archivo.')\n",
        "    except Exception as exc_upload:\n",
        "        question_summary['error'] = f\"Fallo en subida: {exc_upload}\"\n",
        "\n",
        "if question_summary['path']:\n",
        "    to_wav_mono_16k(question_summary['path'], QUESTION_WAV)\n",
        "    question_summary['duration_s'] = round(ffprobe_duration(QUESTION_WAV), 2)\n",
        "\n",
        "ASR_TEXT = ''\n",
        "ASR_LANG = 'desconocido'\n",
        "ASR_TIME = None\n",
        "\n",
        "try:\n",
        "    import whisper\n",
        "    model_name = 'small'\n",
        "    whisper_model = whisper.load_model(model_name)\n",
        "    start = time.time()\n",
        "    result = whisper_model.transcribe(QUESTION_WAV, language=None)\n",
        "    ASR_TIME = round(time.time() - start, 2)\n",
        "    ASR_TEXT = result.get('text', '').strip()\n",
        "    ASR_LANG = result.get('language', 'auto')\n",
        "except Exception as exc:\n",
        "    question_summary['error'] = f\"Whisper falló: {exc}\"\n",
        "\n",
        "RESULTS['asr'] = {\n",
        "    'text': ASR_TEXT,\n",
        "    'language': ASR_LANG,\n",
        "    'time_s': ASR_TIME,\n",
        "    'audio_path': QUESTION_WAV,\n",
        "    'mode': question_summary['mode']\n",
        "}\n",
        "\n",
        "print(json.dumps({'status': 'ok' if ASR_TEXT else 'warning', 'text': ASR_TEXT, 'language': ASR_LANG, 'time_s': ASR_TIME}, ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    plt.figure(figsize=(4,3))\n",
        "    plt.bar(['ASR'], [ASR_TIME or 0], color='steelblue')\n",
        "    plt.title('Tiempo de Whisper (s)')\n",
        "    plt.ylabel('segundos')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ASR_METRICS_PNG)\n",
        "    plt.close()\n",
        "except Exception as exc:\n",
        "    print(f\"[Celda 5] No se pudo generar gráfico ASR: {exc}\")\n",
        "\n",
        "if ASR_TEXT:\n",
        "    try:\n",
        "        display(Audio(QUESTION_WAV))\n",
        "    except Exception:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 6 - LLM local (Qwen2.5-3B-Instruct) + alternativa Flan-T5\n",
        "import json, time\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEFAULT_LLM = 'Qwen/Qwen2.5-3B-Instruct'\n",
        "FALLBACK_LLM = 'google/flan-t5-base'\n",
        "llm_report = {'model': DEFAULT_LLM, 'fallback': False, 'time_s': None, 'response': None, 'error': None}\n",
        "\n",
        "prompt = f\"Responde en español en 1–3 oraciones. Pregunta: {RESULTS.get('asr', {}).get('text', '')}\"\n",
        "if not prompt.strip():\n",
        "    prompt = 'Responde en español en 1–3 oraciones una descripción genérica del flujo ASR-LLM-TTS.'\n",
        "\n",
        "try:\n",
        "    load_kwargs = {}\n",
        "    if torch.cuda.is_available():\n",
        "        load_kwargs.update({'device_map': 'auto', 'torch_dtype': torch.float16})\n",
        "    tokenizer = AutoTokenizer.from_pretrained(DEFAULT_LLM)\n",
        "    model = AutoModelForCausalLM.from_pretrained(DEFAULT_LLM, **load_kwargs)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    start = time.time()\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "    output_tokens = model.generate(**inputs, max_new_tokens=120, temperature=0.7, top_p=0.9, repetition_penalty=1.1)\n",
        "    response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
        "    if response.startswith(prompt):\n",
        "        response = response[len(prompt):].strip()\n",
        "    llm_report['response'] = response.strip()\n",
        "    llm_report['time_s'] = round(time.time() - start, 2)\n",
        "except Exception as exc:\n",
        "    llm_report['error'] = str(exc)\n",
        "    llm_report['fallback'] = True\n",
        "    llm_report['model'] = FALLBACK_LLM\n",
        "    print(f\"[Celda 6] Fallo con {DEFAULT_LLM}: {exc}. Intentando fallback {FALLBACK_LLM}.\")\n",
        "    try:\n",
        "        text_gen = pipeline('text2text-generation', model=FALLBACK_LLM)\n",
        "        start = time.time()\n",
        "        response = text_gen(prompt, max_new_tokens=120)[0]['generated_text']\n",
        "        llm_report['response'] = response.strip()\n",
        "        llm_report['time_s'] = round(time.time() - start, 2)\n",
        "    except Exception as exc_fb:\n",
        "        llm_report['error'] = f\"Fallback falló: {exc_fb}\"\n",
        "\n",
        "RESULTS['llm'] = llm_report\n",
        "print(json.dumps({'model': llm_report['model'], 'time_s': llm_report['time_s'], 'fallback': llm_report['fallback']}, ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    plt.figure(figsize=(4,3))\n",
        "    values = [llm_report['time_s'] or 0]\n",
        "    plt.bar(['LLM'], values, color='salmon')\n",
        "    plt.title('Tiempo de generación LLM (s)')\n",
        "    plt.ylabel('segundos')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(LLM_METRICS_PNG)\n",
        "    plt.close()\n",
        "except Exception as exc:\n",
        "    print(f\"[Celda 6] No se pudo generar gráfico LLM: {exc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 7 - TTS (xTTS v2) + Comparación voz base\n",
        "import json, time\n",
        "from IPython.display import Audio\n",
        "from TTS.api import TTS as TTS_API\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tts_summary = {\n",
        "    'clone_model': 'tts_models/multilingual/multi-dataset/xtts_v2',\n",
        "    'base_model': 'tts_models/es/css10/vits',\n",
        "    'clone_time_s': None,\n",
        "    'base_time_s': None,\n",
        "    'clone_duration_s': None,\n",
        "    'base_duration_s': None,\n",
        "    'error': None\n",
        "}\n",
        "\n",
        "response_text = RESULTS.get('llm', {}).get('response') or 'Respuesta de prueba para síntesis.'\n",
        "\n",
        "try:\n",
        "    tts_clone = TTS_API(tts_summary['clone_model'], gpu=torch.cuda.is_available(), progress_bar=False)\n",
        "    start = time.time()\n",
        "    tts_clone.tts_to_file(text=response_text, speaker_wav=SPEAKER_WAV if os.path.exists(SPEAKER_WAV) else None, language='es', file_path=CLONED_WAV)\n",
        "    tts_summary['clone_time_s'] = round(time.time() - start, 2)\n",
        "    tts_summary['clone_duration_s'] = round(ffprobe_duration(CLONED_WAV), 2)\n",
        "except Exception as exc:\n",
        "    tts_summary['error'] = f\"Clonado falló: {exc}\"\n",
        "    print(f\"[Celda 7] Error en clonación: {exc}\")\n",
        "\n",
        "try:\n",
        "    tts_base = TTS_API(tts_summary['base_model'], gpu=torch.cuda.is_available(), progress_bar=False)\n",
        "    start = time.time()\n",
        "    tts_base.tts_to_file(text=response_text, file_path=BASE_WAV)\n",
        "    tts_summary['base_time_s'] = round(time.time() - start, 2)\n",
        "    tts_summary['base_duration_s'] = round(ffprobe_duration(BASE_WAV), 2)\n",
        "except Exception as exc:\n",
        "    if tts_summary['error']:\n",
        "        tts_summary['error'] += f' | Base falló: {exc}'\n",
        "    else:\n",
        "        tts_summary['error'] = f'Base falló: {exc}'\n",
        "    print(f\"[Celda 7] Error en voz base: {exc}\")\n",
        "\n",
        "RESULTS['tts'] = {\n",
        "    'clone_path': CLONED_WAV if os.path.exists(CLONED_WAV) else None,\n",
        "    'base_path': BASE_WAV if os.path.exists(BASE_WAV) else None,\n",
        "    'clone_time_s': tts_summary['clone_time_s'],\n",
        "    'base_time_s': tts_summary['base_time_s'],\n",
        "    'clone_duration_s': tts_summary['clone_duration_s'],\n",
        "    'base_duration_s': tts_summary['base_duration_s'],\n",
        "    'error': tts_summary['error']\n",
        "}\n",
        "\n",
        "print(json.dumps(RESULTS['tts'], indent=2, ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    plt.figure(figsize=(5,3))\n",
        "    labels = ['Clonada', 'Base']\n",
        "    times = [tts_summary['clone_time_s'] or 0, tts_summary['base_time_s'] or 0]\n",
        "    plt.bar(labels, times, color=['#4c72b0', '#55a868'])\n",
        "    plt.ylabel('Tiempo (s)')\n",
        "    plt.title('Comparación de tiempos TTS')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(TTS_TIMES_PNG)\n",
        "    plt.close()\n",
        "except Exception as exc:\n",
        "    print(f\"[Celda 7] No se pudo generar gráfico de tiempos TTS: {exc}\")\n",
        "\n",
        "if os.path.exists(CLONED_WAV):\n",
        "    try:\n",
        "        display(Audio(CLONED_WAV))\n",
        "    except Exception:\n",
        "        pass\n",
        "if os.path.exists(BASE_WAV):\n",
        "    try:\n",
        "        display(Audio(BASE_WAV))\n",
        "    except Exception:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 8 - Pipeline end-to-end (función + demo)\n",
        "import json, time\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def asr_llm_tts_pipeline(question_mode='record', lang_hint='auto'):\n",
        "    summary = {'question_mode': question_mode, 'lang_hint': lang_hint, 'steps': {}, 'error': None}\n",
        "    try:\n",
        "        if question_mode == 'record':\n",
        "            try:\n",
        "                question_path = record_audio(out_wav=QUESTION_RAW_WAV, sr=16000, autoplay=False)\n",
        "            except Exception as exc:\n",
        "                print(f\"[Pipeline] Grabación falló ({exc}). Cambiando a upload.\")\n",
        "                question_mode = 'upload'\n",
        "                summary['question_mode'] = 'upload'\n",
        "        if question_mode == 'upload':\n",
        "            from google.colab import files  # type: ignore\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                tmp_name = list(uploaded.keys())[0]\n",
        "                tmp_path = os.path.join(paths['audios'], tmp_name)\n",
        "                with open(tmp_path, 'wb') as f:\n",
        "                    f.write(uploaded[tmp_name])\n",
        "                question_path = tmp_path\n",
        "            else:\n",
        "                raise RuntimeError('No se subió archivo para la pregunta.')\n",
        "        to_wav_mono_16k(question_path, QUESTION_WAV)\n",
        "        duration = round(ffprobe_duration(QUESTION_WAV), 2)\n",
        "        summary['steps']['input_audio'] = {'path': QUESTION_WAV, 'duration_s': duration}\n",
        "\n",
        "        import whisper\n",
        "        model = whisper.load_model('small')\n",
        "        start = time.time()\n",
        "        result = model.transcribe(QUESTION_WAV, language=None if lang_hint == 'auto' else lang_hint)\n",
        "        asr_time = round(time.time() - start, 2)\n",
        "        asr_text = result.get('text', '').strip()\n",
        "        asr_lang = result.get('language', lang_hint)\n",
        "        summary['steps']['asr'] = {'text': asr_text, 'language': asr_lang, 'time_s': asr_time}\n",
        "\n",
        "        from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "        import torch\n",
        "        prompt = f\"Responde en español en 1–3 oraciones. Pregunta: {asr_text}\"\n",
        "        response_text = ''\n",
        "        model_name = 'Qwen/Qwen2.5-3B-Instruct'\n",
        "        fallback = False\n",
        "        start = time.time()\n",
        "        try:\n",
        "            load_kwargs = {}\n",
        "            if torch.cuda.is_available():\n",
        "                load_kwargs.update({'device_map': 'auto', 'torch_dtype': torch.float16})\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            model_llm = AutoModelForCausalLM.from_pretrained(model_name, **load_kwargs)\n",
        "            inputs = tokenizer(prompt, return_tensors='pt').to(model_llm.device)\n",
        "            outputs = model_llm.generate(**inputs, max_new_tokens=120, temperature=0.7, top_p=0.9, repetition_penalty=1.1)\n",
        "            response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            if response_text.startswith(prompt):\n",
        "                response_text = response_text[len(prompt):].strip()\n",
        "        except Exception as exc:\n",
        "            fallback = True\n",
        "            pipe = pipeline('text2text-generation', model='google/flan-t5-base')\n",
        "            response_text = pipe(prompt, max_new_tokens=120)[0]['generated_text']\n",
        "        llm_time = round(time.time() - start, 2)\n",
        "        summary['steps']['llm'] = {'text': response_text.strip(), 'time_s': llm_time, 'fallback': fallback}\n",
        "\n",
        "        from TTS.api import TTS as TTS_API\n",
        "        import torch\n",
        "        tts_clone = TTS_API('tts_models/multilingual/multi-dataset/xtts_v2', gpu=torch.cuda.is_available(), progress_bar=False)\n",
        "        start = time.time()\n",
        "        tts_clone.tts_to_file(text=response_text, speaker_wav=SPEAKER_WAV if os.path.exists(SPEAKER_WAV) else None, language='es', file_path=CLONED_WAV)\n",
        "        clone_time = round(time.time() - start, 2)\n",
        "        clone_dur = round(ffprobe_duration(CLONED_WAV), 2)\n",
        "        tts_base = TTS_API('tts_models/es/css10/vits', gpu=torch.cuda.is_available(), progress_bar=False)\n",
        "        start = time.time()\n",
        "        tts_base.tts_to_file(text=response_text, file_path=BASE_WAV)\n",
        "        base_time = round(time.time() - start, 2)\n",
        "        base_dur = round(ffprobe_duration(BASE_WAV), 2)\n",
        "        summary['steps']['tts'] = {\n",
        "            'clone_path': CLONED_WAV,\n",
        "            'base_path': BASE_WAV,\n",
        "            'clone_time_s': clone_time,\n",
        "            'base_time_s': base_time,\n",
        "            'clone_duration_s': clone_dur,\n",
        "            'base_duration_s': base_dur\n",
        "        }\n",
        "\n",
        "        summary['total_time_s'] = round(sum(filter(None, [clone_time, base_time, llm_time, asr_time])), 2)\n",
        "    except Exception as exc:\n",
        "        summary['error'] = str(exc)\n",
        "        print(f\"[Pipeline] Error: {exc}\")\n",
        "    return summary\n",
        "\n",
        "pipeline_result = None\n",
        "try:\n",
        "    pipeline_result = asr_llm_tts_pipeline(question_mode='record', lang_hint='auto')\n",
        "except Exception as exc:\n",
        "    print(f\"[Celda 8] Pipeline en modo record falló: {exc}\")\n",
        "\n",
        "if pipeline_result:\n",
        "    RESULTS['pipeline'] = pipeline_result\n",
        "    save_results(RESULTS, RESULTS_JSON)\n",
        "    print(json.dumps({'status': 'ok', 'pipeline': pipeline_result}, indent=2, ensure_ascii=False))\n",
        "    if pipeline_result.get('steps', {}).get('tts', {}):\n",
        "        if pipeline_result['steps']['tts'].get('clone_path'):\n",
        "            try:\n",
        "                display(Audio(pipeline_result['steps']['tts']['clone_path']))\n",
        "            except Exception:\n",
        "                pass\n",
        "        if pipeline_result['steps']['tts'].get('base_path'):\n",
        "            try:\n",
        "                display(Audio(pipeline_result['steps']['tts']['base_path']))\n",
        "            except Exception:\n",
        "                pass\n",
        "else:\n",
        "    print('[Celda 8] Pipeline no se completó. Revisa errores previos.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 9 - Pruebas automáticas mínimas\n",
        "import json, time, math\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "results_tests = []\n",
        "\n",
        "def report_test(name, status, detail):\n",
        "    results_tests.append({'test': name, 'status': status, 'detail': detail})\n",
        "    print(json.dumps(results_tests[-1], ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    sr = 16000\n",
        "    t = np.linspace(0, 2, int(sr*2), endpoint=False)\n",
        "    tone = 0.1 * np.sin(2 * np.pi * 440 * t)\n",
        "    tone_path = os.path.join(paths['outputs'], 'tone.wav')\n",
        "    sf.write(tone_path, tone, sr)\n",
        "    converted_path = os.path.join(paths['outputs'], 'tone_16k.wav')\n",
        "    to_wav_mono_16k(tone_path, converted_path)\n",
        "    duration = ffprobe_duration(converted_path)\n",
        "    status = 'OK' if duration > 0 else 'FAIL'\n",
        "    detail = f'duración={duration:.2f}s'\n",
        "    report_test('audio_loopback', status, detail)\n",
        "except Exception as exc:\n",
        "    report_test('audio_loopback', 'FAIL', str(exc))\n",
        "\n",
        "try:\n",
        "    phrase = 'Hola, este es un test automático.'\n",
        "    tts_base_path = os.path.join(paths['outputs'], 'tts_test.wav')\n",
        "    from TTS.api import TTS as TTS_API\n",
        "    tts_tmp = TTS_API('tts_models/es/css10/vits', gpu=torch.cuda.is_available(), progress_bar=False)\n",
        "    tts_tmp.tts_to_file(text=phrase, file_path=tts_base_path)\n",
        "    to_wav_mono_16k(tts_base_path, QUESTION_WAV)\n",
        "    import whisper\n",
        "    model = whisper.load_model('tiny')\n",
        "    result = model.transcribe(QUESTION_WAV, language='es')\n",
        "    text = result.get('text', '').strip()\n",
        "    status = 'OK' if text else 'SKIP'\n",
        "    detail = text if text else 'No se obtuvo transcripción, posiblemente ruido.'\n",
        "    report_test('asr_dummy', status, detail)\n",
        "except Exception as exc:\n",
        "    report_test('asr_dummy', 'SKIP', f'Whisper/TTS no disponible: {exc}')\n",
        "\n",
        "try:\n",
        "    question = '¿Qué es la gravedad?'\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "    import torch\n",
        "    load_kwargs = {}\n",
        "    if torch.cuda.is_available():\n",
        "        load_kwargs.update({'device_map': 'auto', 'torch_dtype': torch.float16})\n",
        "    tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-3B-Instruct')\n",
        "    model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-3B-Instruct', **load_kwargs)\n",
        "    inputs = tokenizer(question, return_tensors='pt').to(model.device)\n",
        "    output = model.generate(**inputs, max_new_tokens=120, temperature=0.7, top_p=0.9)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    word_count = len(response.split())\n",
        "    status = 'OK' if 5 <= word_count <= 200 else 'FAIL'\n",
        "    report_test('llm_smoke', status, f'{word_count} palabras')\n",
        "except Exception as exc:\n",
        "    try:\n",
        "        text_gen = pipeline('text2text-generation', model='google/flan-t5-base')\n",
        "        response = text_gen(question)[0]['generated_text']\n",
        "        word_count = len(response.split())\n",
        "        status = 'OK' if 5 <= word_count <= 200 else 'FAIL'\n",
        "        report_test('llm_smoke', status, f'Fallback {word_count} palabras')\n",
        "    except Exception as exc_fb:\n",
        "        report_test('llm_smoke', 'SKIP', f'No fue posible cargar LLM: {exc_fb}')\n",
        "\n",
        "try:\n",
        "    text = 'Prueba de voz clonada.'\n",
        "    base_path = os.path.join(paths['outputs'], 'tts_smoke.wav')\n",
        "    from TTS.api import TTS as TTS_API\n",
        "    tts_tmp = TTS_API('tts_models/es/css10/vits', gpu=torch.cuda.is_available(), progress_bar=False)\n",
        "    tts_tmp.tts_to_file(text=text, file_path=base_path)\n",
        "    duration = ffprobe_duration(base_path)\n",
        "    status = 'OK' if duration > 0.2 else 'FAIL'\n",
        "    report_test('tts_smoke', status, f'duración={duration:.2f}s')\n",
        "except Exception as exc:\n",
        "    report_test('tts_smoke', 'SKIP', str(exc))\n",
        "\n",
        "try:\n",
        "    print('Iniciando test voluntario de grabación. Puedes omitirlo dejando pasar 30 s.')\n",
        "    start = time.time()\n",
        "    try:\n",
        "        record_audio(out_wav=os.path.join(paths['audios'], 'test_record.wav'), sr=16000, autoplay=False, timeslice_ms=300)\n",
        "        report_test('record_audio_manual', 'OK', 'Grabación disponible')\n",
        "    except Exception as exc:\n",
        "        if time.time() - start > 30:\n",
        "            report_test('record_audio_manual', 'SKIP', f'Sin interacción del usuario: {exc}')\n",
        "        else:\n",
        "            report_test('record_audio_manual', 'FAIL', str(exc))\n",
        "except Exception as exc:\n",
        "    report_test('record_audio_manual', 'SKIP', f'Entorno sin soporte de navegador: {exc}')\n",
        "\n",
        "print('[Celda 9] Resumen de tests:')\n",
        "print(json.dumps(results_tests, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 10 - Troubleshooting interactivo\n",
        "from IPython.display import Markdown, display, Javascript\n",
        "\n",
        "checklist = \"\"\"\n",
        "### Checklist rápido\n",
        "- ¿El navegador concedió permisos al micrófono?\n",
        "- ¿Algún bloqueador de pop-ups o extensiones está interfiriendo?\n",
        "- ¿`timeslice_ms` es muy grande? Prueba valores de 200–400 ms.\n",
        "- Reintenta en Google Chrome estable si usas otro navegador.\n",
        "- Si `MediaRecorder` falla con `audio/webm;codecs=opus`, el código ya intenta un fallback automático.\n",
        "\"\"\"\n",
        "\n",
        "reset_js = \"\"\"\n",
        "(() => {\n",
        "  const existing = document.getElementById('recorder-box');\n",
        "  if (existing) existing.remove();\n",
        "  google.colab.kernel.invokeFunction('notebook.audio_error', ['Reset manual solicitado.'], {});\n",
        "  console.log('Recorder UI reiniciada. Vuelve a ejecutar la celda de grabación.');\n",
        "})();\n",
        "\"\"\"\n",
        "\n",
        "def reset_recorder():\n",
        "    try:\n",
        "        display(Javascript(reset_js))\n",
        "    except Exception as exc:\n",
        "        print(f'No fue posible reiniciar el grabador: {exc}')\n",
        "\n",
        "display(Markdown(checklist))\n",
        "print('[Celda 10] Usa reset_recorder() si necesitas reiniciar la UI del grabador.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celda 11 - Conclusión y guía para exposición\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "summary_md = \"\"\"\n",
        "### Conclusiones\n",
        "- El pipeline completo convierte audio de entrada en texto (Whisper), genera una respuesta corta (LLM) y sintetiza dos voces (clonada y base) para comparar.\n",
        "- Las gráficas generadas muestran los tiempos estimados de cada módulo para facilitar el análisis de rendimiento.\n",
        "- Los resultados consolidados, incluyendo rutas de archivos y métricas, se guardan en `results.json` dentro de la carpeta `outputs/`.\n",
        "\n",
        "### Cómo exponer el demo\n",
        "1. Muestra la voz de referencia y explica la clonación (escucha ambos audios).\n",
        "2. Ejecuta la celda del pipeline end-to-end y enseña los tiempos en pantalla.\n",
        "3. Usa las gráficas (`asr_metrics.png`, `llm_metrics.png`, `tts_tiempos.png`) para comentar diferencias.\n",
        "\n",
        "### Próximos pasos sugeridos\n",
        "- Probar LLMs más grandes o especializados para respuestas detalladas.\n",
        "- Incluir diarización y supresión de ruido antes de Whisper para ambientes complejos.\n",
        "- Explorar control de prosodia multilingüe en la síntesis clonada.\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(summary_md))\n",
        "print('[Celda 11] Conclusión mostrada. ¡Listo para presentar!')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}