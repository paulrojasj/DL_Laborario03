{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 — ASR + LLM + TTS end-to-end\n",
    "Este cuaderno reproduce el flujo sugerido por el profesor: grabar audio desde Colab, transcribirlo con Whisper, generar una respuesta breve con un LLM e inferir audio con Coqui TTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper # NO whisper\n",
    "!pip install jiwer\n",
    "!pip -q install transformers accelerate sentencepiece\n",
    "!pip install coqui-tts  # usar coqui-tts (no el paquete \"tts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabación de audio\n",
    "Reutiliza el widget proporcionado en el notebook de referencia del profesor para asegurar compatibilidad con Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript, HTML, display, Audio\n",
    "from google.colab import output\n",
    "import base64, subprocess, uuid, os, pathlib\n",
    "\n",
    "# @title Grabación de audio\n",
    "# @markdown Lo necesitas para grabar audio desde Colab. Intenta mejorarlo.\n",
    "def record(out_webm=None, out_wav=None, sr=16000, autoplay=False):\n",
    "    if out_webm is None:\n",
    "        out_webm = f\"/content/rec_{uuid.uuid4().hex}.webm\"\n",
    "    if out_wav is None:\n",
    "        out_wav = f\"/content/rec_{uuid.uuid4().hex}.wav\"\n",
    "\n",
    "    js = Javascript(r\"\"\"\n",
    "    async function recorderUIOnce(){\n",
    "      const existing = document.getElementById('recorder-box');\n",
    "      if (existing) { existing.remove(); }\n",
    "\n",
    "      const box = document.createElement('div');\n",
    "      box.id = 'recorder-box';\n",
    "      box.style.cssText = 'padding:12px;margin:8px 0;border:1px solid #ddd;border-radius:10px;display:inline-flex;gap:8px;align-items:center;font-family:sans-serif';\n",
    "\n",
    "      const dot = document.createElement('span');\n",
    "      dot.style.cssText = 'width:10px;height:10px;border-radius:50%;background:#bbb';\n",
    "\n",
    "      const startBtn = document.createElement('button');\n",
    "      startBtn.textContent = 'Grabar';\n",
    "      startBtn.style.cssText = 'padding:6px 10px';\n",
    "\n",
    "      const stopBtn = document.createElement('button');\n",
    "      stopBtn.textContent = 'Parar';\n",
    "      stopBtn.style.cssText = 'padding:6px 10px';\n",
    "      stopBtn.disabled = true;\n",
    "\n",
    "      const msg = document.createElement('span');\n",
    "      msg.textContent = 'Listo para grabar';\n",
    "      msg.style.minWidth = '180px';\n",
    "\n",
    "      box.append(dot, startBtn, stopBtn, msg);\n",
    "      document.body.appendChild(box);\n",
    "\n",
    "      let stream, rec, chunks = [];\n",
    "\n",
    "      function setRec(on){\n",
    "        dot.style.background = on ? '#e74c3c' : '#bbb';\n",
    "        startBtn.disabled = on;\n",
    "        stopBtn.disabled = !on;\n",
    "        msg.textContent = on ? 'Grabando…' : 'Listo para grabar';\n",
    "      }\n",
    "\n",
    "      return await new Promise(async (resolve, reject) => {\n",
    "        try {\n",
    "          stream = await navigator.mediaDevices.getUserMedia({ audio:true });\n",
    "          rec = new MediaRecorder(stream);\n",
    "        } catch (err) {\n",
    "          box.remove();\n",
    "          reject('No se pudo acceder al micrófono: ' + err);\n",
    "          return;\n",
    "        }\n",
    "\n",
    "        rec.ondataavailable = e => { if (e.data && e.data.size > 0) chunks.push(e.data); };\n",
    "\n",
    "        rec.onstop = async () => {\n",
    "          try {\n",
    "            const blob = new Blob(chunks, {type:'audio/webm;codecs=opus'});\n",
    "            const buf = await blob.arrayBuffer();\n",
    "            const b64 = btoa(String.fromCharCode(...new Uint8Array(buf)));\n",
    "            stream.getTracks().forEach(t => t.stop());\n",
    "            box.remove();\n",
    "            resolve(b64);\n",
    "          } catch (err) {\n",
    "            stream.getTracks().forEach(t => t.stop());\n",
    "            box.remove();\n",
    "            reject(err);\n",
    "          }\n",
    "        };\n",
    "\n",
    "        startBtn.onclick = () => { chunks = []; rec.start(); setRec(true); };\n",
    "        stopBtn.onclick = () => {\n",
    "          if (rec && rec.state === 'recording') {\n",
    "            rec.stop();\n",
    "            setRec(false);\n",
    "          }\n",
    "        };\n",
    "      });\n",
    "    }\n",
    "    \"\"\")\n",
    "    display(js)\n",
    "\n",
    "    b64 = output.eval_js(\"recorderUIOnce()\")\n",
    "    with open(out_webm, \"wb\") as f:\n",
    "        f.write(base64.b64decode(b64))\n",
    "\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\", \"-y\", \"-i\", out_webm, \"-ac\", \"1\", \"-ar\", str(sr), out_wav\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    try:\n",
    "        os.remove(out_webm)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    display(Audio(filename=out_wav, autoplay=autoplay))\n",
    "    return out_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = record(out_wav=\"/content/input.wav\", autoplay=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Speech Recognition (ASR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import whisper, time\n",
    "from jiwer import wer\n",
    "\n",
    "MODEL = \"turbo\"   # opciones disponibles: tiny, base, small, medium, large, turbo\n",
    "m = whisper.load_model(MODEL)\n",
    "audio_in = \"input.wav\"\n",
    "\n",
    "t0 = time.time()\n",
    "out = m.transcribe(audio_in, language=\"en\", task=\"transcribe\", verbose=False)\n",
    "t1 = time.time()\n",
    "\n",
    "user_text = out[\"text\"].strip()\n",
    "print(\"ASR:\", user_text)\n",
    "print(f\"Latency: {t1 - t0:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM — Generación de respuesta corta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "model_id = \"google/flan-t5-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "mdl = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=mdl, tokenizer=tok)\n",
    "prompt = f\"Eres un asistente útil. Responde en 1-2 oraciones y sé directo. Pregunta: {user_text}\"\n",
    "resp = pipe(prompt, max_new_tokens=128)[0][\"generated_text\"].strip()\n",
    "print(\"LLM:\", resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS — Síntesis con Coqui TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "\n",
    "print(tts.speakers)\n",
    "\n",
    "tts.tts_to_file(\n",
    "    text=resp,\n",
    "    # speaker_wav=\"ref_voice.wav\",    # tu audio de referencia (5–10 s)\n",
    "                                      # procura que sea audio de calidad\n",
    "    speaker='Claribel Dervla',\n",
    "    language=\"es\",\n",
    "    file_path=\"respuesta.wav\"\n",
    ")\n",
    "\n",
    "display(Audio(filename=\"respuesta.wav\", autoplay=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}